{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Immigration Data Analytics (Capstone Project)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project uses I94 Immigration Data from the US National Tourism and Trade Office (https://travel.trade.gov/research/reports/i94/historical/2016.html) and combines it with U.S. City Demographic Data (see here https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/) using Airport Code Tables.\n",
    "The resulting dataschema can be used to easily run analytics queries on the immigration data and discover demographic and geographic dependencies. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "\n",
    "Generally the project cleans and simplifies the I94 data and enhances it with airport and city data from the other two data sources. From the I94 dataset, data about the immigrant, the target destination and the time and type of immigration event will be used. This will be combined with city demographic data from the us-cities-demographics dataset as well as airport name and location for the destination city.\n",
    "In the end the raw data will be extracted from the input files via an ETL pipeline and converted to a table star schema where the immigration act fact will be separated from dimension tables like city, immigrant and airports.\n",
    "\n",
    "In order to get a general overview of the data, the python pandas library will be used to explore it in the following.\n",
    "\n",
    "### Describe and Gather Data \n",
    "\n",
    "#### I94 Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr  ...  entdepu  matflag  biryear   dtaddto  gender insnum  \\\n",
       "0      1.0      HI  ...      NaN        M   1955.0  07202016       F    NaN   \n",
       "1      1.0      TX  ...      NaN        M   1990.0  10222016       M    NaN   \n",
       "2      1.0      FL  ...      NaN        M   1940.0  07052016       M    NaN   \n",
       "3      1.0      CA  ...      NaN        M   1991.0  10272016       M    NaN   \n",
       "4      3.0      NY  ...      NaN        M   1997.0  07042016       F    NaN   \n",
       "\n",
       "  airline        admnum  fltno  visatype  \n",
       "0      JL  5.658267e+10  00782        WT  \n",
       "1     *GA  9.436200e+10  XBLNG        B2  \n",
       "2      LH  5.578047e+10  00464        WT  \n",
       "3      QR  9.478970e+10  00739        B2  \n",
       "4     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfImmigration = pd.read_csv('./sample_data/immigration_data_sample.csv')\n",
    "dfImmigration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using _I94_SAS_Labels_Descriptions.SAS_ we can see that each immigration record has \n",
    "\n",
    "- an **unique id** (cicid), \n",
    "- the **date of arrival** in various forms and formats (i94yr, i94mon, arrdate, dtadfile), \n",
    "- some information about the **immigrant** (biryear, i94res, gender)\n",
    "- the **mode of travel** used (i94mode)\n",
    "- the type of the visa, i. e. the **reason for the immigration** like pleasure or business\n",
    "- the **destination** city (i94res)\n",
    "- the airline/**flight number**\n",
    "\n",
    "These are all interesting information which we can use in the final dataset. However we can also see that\n",
    "\n",
    "- some columns contain redundant information (i94yr and dtadfile)\n",
    "- some columns not usable (occup) because no description of codes available\n",
    "- some columns have the wrong datatype (lots of float which should be integer)\n",
    "- some columns using codes (corresponding values are in I94_SAS_Labels_Descriptions) which will have to be transformed to their final values\n",
    "- some columns might contain null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0\n",
       "cicid            0\n",
       "i94yr            0\n",
       "i94mon           0\n",
       "i94cit           0\n",
       "i94res           0\n",
       "i94port          0\n",
       "arrdate          0\n",
       "i94mode          0\n",
       "i94addr         59\n",
       "depdate         49\n",
       "i94bir           0\n",
       "i94visa          0\n",
       "count            0\n",
       "dtadfile         0\n",
       "visapost       618\n",
       "occup          996\n",
       "entdepa          0\n",
       "entdepd         46\n",
       "entdepu       1000\n",
       "matflag         46\n",
       "biryear          0\n",
       "dtaddto          0\n",
       "gender         141\n",
       "insnum         965\n",
       "airline         33\n",
       "admnum           0\n",
       "fltno            8\n",
       "visatype         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfImmigration.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US Cities Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>31.3</td>\n",
       "      <td>65212.0</td>\n",
       "      <td>60664.0</td>\n",
       "      <td>125876</td>\n",
       "      <td>9367.0</td>\n",
       "      <td>8129.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>TX</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>31.3</td>\n",
       "      <td>65212.0</td>\n",
       "      <td>60664.0</td>\n",
       "      <td>125876</td>\n",
       "      <td>9367.0</td>\n",
       "      <td>8129.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>TX</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>33222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>31.3</td>\n",
       "      <td>65212.0</td>\n",
       "      <td>60664.0</td>\n",
       "      <td>125876</td>\n",
       "      <td>9367.0</td>\n",
       "      <td>8129.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>TX</td>\n",
       "      <td>White</td>\n",
       "      <td>95487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>31.3</td>\n",
       "      <td>65212.0</td>\n",
       "      <td>60664.0</td>\n",
       "      <td>125876</td>\n",
       "      <td>9367.0</td>\n",
       "      <td>8129.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>TX</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>31.3</td>\n",
       "      <td>65212.0</td>\n",
       "      <td>60664.0</td>\n",
       "      <td>125876</td>\n",
       "      <td>9367.0</td>\n",
       "      <td>8129.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>TX</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>14449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>57054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>3731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Asian</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Yuma</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.4</td>\n",
       "      <td>48298.0</td>\n",
       "      <td>45847.0</td>\n",
       "      <td>94145</td>\n",
       "      <td>7182.0</td>\n",
       "      <td>19326.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>AZ</td>\n",
       "      <td>White</td>\n",
       "      <td>69691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         City    State  Median Age  Male Population  Female Population  \\\n",
       "2727  Abilene    Texas        31.3          65212.0            60664.0   \n",
       "1403  Abilene    Texas        31.3          65212.0            60664.0   \n",
       "1533  Abilene    Texas        31.3          65212.0            60664.0   \n",
       "245   Abilene    Texas        31.3          65212.0            60664.0   \n",
       "2880  Abilene    Texas        31.3          65212.0            60664.0   \n",
       "...       ...      ...         ...              ...                ...   \n",
       "2859     Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "1084     Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "2105     Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "1619     Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "875      Yuma  Arizona        33.4          48298.0            45847.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "2727            125876              9367.0        8129.0   \n",
       "1403            125876              9367.0        8129.0   \n",
       "1533            125876              9367.0        8129.0   \n",
       "245             125876              9367.0        8129.0   \n",
       "2880            125876              9367.0        8129.0   \n",
       "...                ...                 ...           ...   \n",
       "2859             94145              7182.0       19326.0   \n",
       "1084             94145              7182.0       19326.0   \n",
       "2105             94145              7182.0       19326.0   \n",
       "1619             94145              7182.0       19326.0   \n",
       "875              94145              7182.0       19326.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "2727                    2.64         TX                              Asian   \n",
       "1403                    2.64         TX                 Hispanic or Latino   \n",
       "1533                    2.64         TX                              White   \n",
       "245                     2.64         TX  American Indian and Alaska Native   \n",
       "2880                    2.64         TX          Black or African-American   \n",
       "...                      ...        ...                                ...   \n",
       "2859                    2.64         AZ  American Indian and Alaska Native   \n",
       "1084                    2.64         AZ                 Hispanic or Latino   \n",
       "2105                    2.64         AZ          Black or African-American   \n",
       "1619                    2.64         AZ                              Asian   \n",
       "875                     2.64         AZ                              White   \n",
       "\n",
       "      Count  \n",
       "2727   2929  \n",
       "1403  33222  \n",
       "1533  95487  \n",
       "245    1813  \n",
       "2880  14449  \n",
       "...     ...  \n",
       "2859   1228  \n",
       "1084  57054  \n",
       "2105   3731  \n",
       "1619   1180  \n",
       "875   69691  \n",
       "\n",
       "[2891 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCities = pd.read_csv('./sample_data/us-cities-demographics.csv', sep=';')\n",
    "dfCities.sort_values(by='City')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this file unsurprisingly contains demographic and population data for US cities. However there is a catch since are multiple rows per city each containing the population count for an ethnic group.\n",
    "\n",
    "This means we will later have to think of a way to consolidate the data into just one row per city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCities.City.unique().size == dfCities.City.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Airport Codes Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also quite mundane is the airport code dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAirportCodes = pd.read_csv('./sample_data/airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAirportCodes.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is a list of global airports, identified by their code and name as well as including their respective location (elevation, coordinates, municipality). Obviously the list also contains lots of small airports which are probably not used for immigration and are therefore not very interesting. However the coordinates column could perhaps be interesting in order to visualize immigration events on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "# df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "# df_spark.write.parquet(\"sas_data\")\n",
    "# df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "### Explore and clean immigration data\n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from airflow.spark.udf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfImmigrationRaw = spark.read.parquet('sample_data/sas_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by selecting only the columns which will be interesting to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "I94SelectedColumns = ['cicid', 'dtadfile', 'biryear', 'i94bir', 'gender', 'I94CIT', 'I94RES', 'i94port', 'i94mode', 'I94VISA', 'dtaddto', 'airline', 'fltno', 'i94addr']\n",
    "I94IntegerColumns = ['cicid', 'biryear', 'i94bir', 'I94CIT', 'I94RES', 'i94mode', 'i94visa']\n",
    "\n",
    "dfImmigration = dfImmigrationRaw.select(*I94SelectedColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will convert the float columns to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+\n",
      "|  cicid|dtadfile|biryear|i94bir|gender|I94CIT|I94RES|i94port|i94mode|i94visa| dtaddto|airline|fltno|i94addr|\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+\n",
      "|5748517|20160430|   1976|    40|     F|   245|   438|    LOS|      1|      1|10292016|     QF|00011|     CA|\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfImmigration = correct_to_integer(dfImmigration, I94IntegerColumns)\n",
    "dfImmigration.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets add an arrival date as a date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+\n",
      "|  cicid|dtadfile|biryear|i94bir|gender|I94CIT|I94RES|i94port|i94mode|i94visa| dtaddto|airline|fltno|i94addr|arrival_date|\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+\n",
      "|5748517|20160430|   1976|    40|     F|   245|   438|    LOS|      1|      1|10292016|     QF|00011|     CA|  2016-04-30|\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfImmigration = dfImmigration.withColumn('arrival_date', to_date(col('dtadfile'), 'yyyyMMdd'))\n",
    "dfImmigration.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can add a meaningful replacement for the i94mode and i94visa columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+----+--------+\n",
      "|  cicid|dtadfile|biryear|i94bir|gender|I94CIT|I94RES|i94port|i94mode|i94visa| dtaddto|airline|fltno|i94addr|arrival_date|mode|  reason|\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+----+--------+\n",
      "|5748517|20160430|   1976|    40|     F|   245|   438|    LOS|      1|      1|10292016|     QF|00011|     CA|  2016-04-30| air|business|\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+----+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfImmigration = dfImmigration \\\n",
    "                    .withColumn('mode', udfI94Mode(col('i94mode'))) \\\n",
    "                    .withColumn('reason', udfI94VISA(col('I94VISA')))\n",
    "dfImmigration.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the i94res column to add residential information of the immigrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+----+--------+---------+\n",
      "|  cicid|dtadfile|biryear|i94bir|gender|I94CIT|I94RES|i94port|i94mode|i94visa| dtaddto|airline|fltno|i94addr|arrival_date|mode|  reason| resident|\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+----+--------+---------+\n",
      "|5748517|20160430|   1976|    40|     F|   245|   438|    LOS|      1|      1|10292016|     QF|00011|     CA|  2016-04-30| air|business|australia|\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+----+--------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfImmigration = dfImmigration \\\n",
    "                    .withColumn('resident', udfCityOrResident(col('I94RES')))\n",
    "dfImmigration.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map i94port to the corresponding city and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+----+--------+---------+----------------+-----------------+\n",
      "|  cicid|dtadfile|biryear|i94bir|gender|I94CIT|I94RES|i94port|i94mode|i94visa| dtaddto|airline|fltno|i94addr|arrival_date|mode|  reason| resident|destination_city|destination_state|\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+----+--------+---------+----------------+-----------------+\n",
      "|5748517|20160430|   1976|    40|     F|   245|   438|    LOS|      1|      1|10292016|     QF|00011|     CA|  2016-04-30| air|business|australia|     los angeles|        ca       |\n",
      "+-------+--------+-------+------+------+------+------+-------+-------+-------+--------+-------+-----+-------+------------+----+--------+---------+----------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfImmigration = dfImmigration \\\n",
    "                    .withColumn('destination_city', udfDestCity(col('i94port'))) \\\n",
    "                    .withColumn('destination_state', udfDestState(col('i94port')))\n",
    "dfImmigration.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove obsolete columns and rename columns for better understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----+--------+---+----------------+-----------------+------------+-------------+--------------+-------+------------+\n",
      "|immigration_id|arrival_date|mode|  reason|age|destination_city|destination_state|person_birth|person_gender|person_country|airline|flightnumber|\n",
      "+--------------+------------+----+--------+---+----------------+-----------------+------------+-------------+--------------+-------+------------+\n",
      "|       5748517|  2016-04-30| air|business| 40|     los angeles|               ca|        1976|            f|     australia|     qf|       00011|\n",
      "+--------------+------------+----+--------+---+----------------+-----------------+------------+-------------+--------------+-------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfImmigrationFinal = dfImmigration \\\n",
    "                    .select( \\\n",
    "                        col('cicid').alias('immigration_id'), 'arrival_date', 'mode', 'reason', col('i94bir').alias('age'), \\\n",
    "                        trim(col('destination_city')).alias('destination_city'), trim(col('destination_state')).alias('destination_state'), \\\n",
    "                       # lower(col('i94addr')), \\\n",
    "                        col('biryear').alias('person_birth'), lower(col('gender')).alias('person_gender'), \\\n",
    "                        col('resident').alias('person_country'),\n",
    "                        lower(col('airline')).alias('airline'), col('fltno').alias('flightnumber')\n",
    "                    )\n",
    "dfImmigrationFinal.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's do a quick check for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----+------+---+----------------+-----------------+------------+-------------+--------------+-------+------------+\n",
      "|immigration_id|arrival_date|mode|reason|age|destination_city|destination_state|person_birth|person_gender|person_country|airline|flightnumber|\n",
      "+--------------+------------+----+------+---+----------------+-----------------+------------+-------------+--------------+-------+------------+\n",
      "|             0|           1|   0|     0|802|          100723|           100723|         802|       414269|             0|  83627|       19549|\n",
      "+--------------+------------+----+------+---+----------------+-----------------+------------+-------------+--------------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfImmigrationFinal.select([count(when(isnull(c), c)).alias(c) for c in dfImmigrationFinal.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*arrival_date*, *mode* and *reason* should not be null, therefore let's drop rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----+--------+---+----------------+-----------------+------------+-------------+--------------+-------+------------+\n",
      "|immigration_id|arrival_date|mode|  reason|age|destination_city|destination_state|person_birth|person_gender|person_country|airline|flightnumber|\n",
      "+--------------+------------+----+--------+---+----------------+-----------------+------------+-------------+--------------+-------+------------+\n",
      "|       5748517|  2016-04-30| air|business| 40|     los angeles|               ca|        1976|            f|     australia|     qf|       00011|\n",
      "|       5748518|  2016-04-30| air|business| 32|     los angeles|               ca|        1984|            f|     australia|     va|       00007|\n",
      "|       5748519|  2016-04-30| air|business| 29|     los angeles|               ca|        1987|            m|     australia|     dl|       00040|\n",
      "+--------------+------------+----+--------+---+----------------+-----------------+------------+-------------+--------------+-------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfImmigrationFinal = dfImmigrationFinal.dropna(subset=['arrival_date', 'mode', 'reason'])\n",
    "dfImmigrationFinal.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As destination_state (extracted from i94port) has fewer null values than i94addr we go with destination_state. Apart from that airline and flightnumber have quite a large number of null values which makes sense, since travel can also happen by land and sea. The person_gender column also has a lot of null values, however for analytical purposes it is probably still better to keep these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore and clean us city data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   City|State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+-------+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|Abilene|Texas|      31.3|          65212|            60664|          125876|              9367|        8129|                  2.64|        TX|American Indian a...| 1813|\n",
      "|Abilene|Texas|      31.3|          65212|            60664|          125876|              9367|        8129|                  2.64|        TX|  Hispanic or Latino|33222|\n",
      "|Abilene|Texas|      31.3|          65212|            60664|          125876|              9367|        8129|                  2.64|        TX|               White|95487|\n",
      "+-------+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCities = spark.read.option('delimiter', ';').option('header', True).csv('./sample_data/us-cities-demographics.csv', sep=';')\n",
    "dfCities.orderBy('City').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|City|State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|Race|Count|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|   0|    0|         0|              3|                3|               0|                13|          13|                    16|         0|   0|    0|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCities.select([count(when(isnull(c), c)).alias(c) for c in dfCities.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----------------+--------+--------------+---------+\n",
      "|        city|median_age|state|total_population|male_pct|household_size|white_pct|\n",
      "+------------+----------+-----+----------------+--------+--------------+---------+\n",
      "|  richardson|      35.5|   tx|          110827|    0.49|          2.83|     0.69|\n",
      "|murfreesboro|      30.2|   tn|          126121|    0.48|           2.6|     0.77|\n",
      "|    alhambra|      41.0|   ca|           85572|    0.49|          2.89|     0.24|\n",
      "+------------+----------+-----+----------------+--------+--------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCitiesFinal = dfCities.filter(col('Race') == 'White').select(\n",
    "    lower(col('City')).alias('city'), col('Median Age').alias('median_age'), \\\n",
    "    lower(col('State Code')).alias('state'), col('Total Population').alias('total_population'), \\\n",
    "    (round(col('Male Population')/col('Total Population'), 2)).alias('male_pct'), col('Average Household Size').alias('household_size'),\n",
    "    (round(col('Count')/col('Total Population'), 2)).alias('white_pct')\n",
    ").drop_duplicates()\n",
    "\n",
    "dfCitiesFinal.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore and clean airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfAirports = spark.read.option('header', True).csv('./sample_data/airport-codes_csv.csv')\n",
    "dfAirports.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove all the small airports and also keep only airports in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "| KABQ|large_airport|Albuquerque Inter...|        5355|       NA|         US|     US-NM| Albuquerque|    KABQ|      ABQ|       ABQ|-106.609001, 35.0...|\n",
      "| KADW|large_airport|  Joint Base Andrews|         280|       NA|         US|     US-MD|Camp Springs|    KADW|      ADW|       ADW|-76.866997, 38.81...|\n",
      "| KAFW|large_airport|Fort Worth Allian...|         722|       NA|         US|     US-TX|  Fort Worth|    KAFW|      AFW|       AFW|-97.3188018799000...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfAirports = dfAirports.filter(col('type') == 'large_airport').filter(col('iso_country') == 'US')\n",
    "dfAirports.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split coordinates into latitude/longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+-------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|              coord|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+-------------------+\n",
      "| KABQ|large_airport|Albuquerque Inter...|        5355|       NA|         US|     US-NM| Albuquerque|    KABQ|      ABQ|       ABQ|-106.609001, 35.0...|{-106.609, 35.0402}|\n",
      "| KADW|large_airport|  Joint Base Andrews|         280|       NA|         US|     US-MD|Camp Springs|    KADW|      ADW|       ADW|-76.866997, 38.81...| {-76.867, 38.8108}|\n",
      "| KAFW|large_airport|Fort Worth Allian...|         722|       NA|         US|     US-TX|  Fort Worth|    KAFW|      AFW|       AFW|-97.3188018799000...|{-97.3188, 32.9876}|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfAirports = dfAirports.withColumn('coord', udfExtractLatLongFromCoords(col('coordinates')))\n",
    "dfAirports.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract state from iso_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+-------------------+-----+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|              coord|state|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+-------------------+-----+\n",
      "| KABQ|large_airport|Albuquerque Inter...|        5355|       NA|         US|     US-NM| Albuquerque|    KABQ|      ABQ|       ABQ|-106.609001, 35.0...|{-106.609, 35.0402}|   nm|\n",
      "| KADW|large_airport|  Joint Base Andrews|         280|       NA|         US|     US-MD|Camp Springs|    KADW|      ADW|       ADW|-76.866997, 38.81...| {-76.867, 38.8108}|   md|\n",
      "| KAFW|large_airport|Fort Worth Allian...|         722|       NA|         US|     US-TX|  Fort Worth|    KAFW|      AFW|       AFW|-97.3188018799000...|{-97.3188, 32.9876}|   tx|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+-------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfAirports = dfAirports.withColumn('state', udfExtractStateFromRegion(col('iso_region')))\n",
    "dfAirports.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute elevation in meters, since this is easier to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+-------------------+-----+---------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|              coord|state|elevation|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+-------------------+-----+---------+\n",
      "| KABQ|large_airport|Albuquerque Inter...|        5355|       NA|         US|     US-NM| Albuquerque|    KABQ|      ABQ|       ABQ|-106.609001, 35.0...|{-106.609, 35.0402}|   nm|     1632|\n",
      "| KADW|large_airport|  Joint Base Andrews|         280|       NA|         US|     US-MD|Camp Springs|    KADW|      ADW|       ADW|-76.866997, 38.81...| {-76.867, 38.8108}|   md|       85|\n",
      "| KAFW|large_airport|Fort Worth Allian...|         722|       NA|         US|     US-TX|  Fort Worth|    KAFW|      AFW|       AFW|-97.3188018799000...|{-97.3188, 32.9876}|   tx|      220|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+-------------------+-----+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfAirports = dfAirports.withColumn('elevation', (col('elevation_ft') * 0.3048).cast('integer'))\n",
    "dfAirports.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select final columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+--------+---------+---------+\n",
      "|                name|        city|state|latitude|longitude|elevation|\n",
      "+--------------------+------------+-----+--------+---------+---------+\n",
      "|albuquerque inter...| albuquerque|   nm|-106.609|  35.0402|     1632|\n",
      "|  joint base andrews|camp springs|   md| -76.867|  38.8108|       85|\n",
      "|fort worth allian...|  fort worth|   tx|-97.3188|  32.9876|      220|\n",
      "+--------------------+------------+-----+--------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfAirportsFinal = dfAirports.select(lower(col('name')).alias('name'), lower(col('municipality')).alias('city'), lower(col('state')).alias('state'), 'coord.latitude', 'coord.longitude', 'elevation')\n",
    "dfAirportsFinal.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see now several cities have more than one airport which is a problem as we can only associate the airport with the immigration event by city. \n",
    "\n",
    "However assuming that these airports are all pretty close to the city, we can just select any of them when there is more than one. In doing so we can still make use of the elevation or latitude/longitude data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      city|count|\n",
      "+----------+-----+\n",
      "|  columbus|    3|\n",
      "|  new york|    3|\n",
      "|charleston|    2|\n",
      "|   chicago|    2|\n",
      "|   spokane|    2|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfAirportsFinal.groupBy('city').agg(count(col('name')).alias('count')).orderBy(desc(col('count'))).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Data Model\n",
    "### 3.1 Conceptual Data Model\n",
    "\n",
    "The following graphic shows the target data model:\n",
    "\n",
    "![Immigration Data Model](data-model.png \"Immigration Data Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data model we should be able to answer the following questions:\n",
    "\n",
    "- from where are people primarily immigrating to the US\n",
    "- what is the primary reason of immigration\n",
    "- what is the average age of immigrants\n",
    "- which cities are handling the most immigrants and by which way of travel\n",
    "- by which way of travel do people come to the US\n",
    "- does the way of travel have influence on immigrants age\n",
    "- show number of immigrations on a map using the airports latitude and longitude\n",
    "- which airlines transport most of the immigrants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build dimPerson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract person columns from the *dfImmigrationFinal* dataset and generate a person_id by hashing all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------------+--------------------+\n",
      "|birth_year|gender|     country|           person_id|\n",
      "+----------+------+------------+--------------------+\n",
      "|      1945|     f|saudi arabia|d26ccba4dab8785ac...|\n",
      "|      1948|     f|      israel|e34309c483fb02c4f...|\n",
      "|      1963|     m|      jordan|27834ff344cfd8099...|\n",
      "+----------+------+------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfPerson = dfImmigrationFinal \\\n",
    "            .select(col('person_birth').alias('birth_year'), col('person_gender').alias('gender'), col('person_country').alias('country')) \\\n",
    "            .drop_duplicates()\n",
    "\n",
    "dfPerson = dfPerson.withColumn('person_id', sha2(concat(*(col(c).cast(\"string\") for c in dfPerson.columns)), 256)) \\\n",
    "            \n",
    "dfPerson.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build dimDestination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract destination columns from the *dfImmigrationFinal* dataset and join with the *dfCitiesFinal* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDestination = dfImmigrationFinal \\\n",
    "                .select(col('destination_city').alias('city'), col('destination_state').alias('state')) \\\n",
    "                .drop_duplicates()\n",
    "\n",
    "dfDestination = dfDestination.withColumn('destination_id', sha2(concat(*(col(c).cast(\"string\") for c in dfDestination.columns)), 256)) \\\n",
    "                .join(dfCitiesFinal, ['city', 'state'], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+--------------------+----------+----------------+--------+--------------+---------+\n",
      "|     city|state|      destination_id|median_age|total_population|male_pct|household_size|white_pct|\n",
      "+---------+-----+--------------------+----------+----------------+--------+--------------+---------+\n",
      "|  ontario|   ca|ea618d825f855e9a9...|      31.0|          171200|     0.5|          3.52|     0.44|\n",
      "|nashville|   tn|c991adef1dbe9df15...|      34.1|          654596|    0.48|          2.39|     0.66|\n",
      "|   mobile|   al|66c26273272bf325d...|      38.0|          194305|    0.47|           2.4|     0.48|\n",
      "|    omaha|   ne|5954c975c184568aa...|      34.2|          443887|    0.49|          2.47|      0.8|\n",
      "|   fresno|   ca|7aa097d84d817b240...|      30.0|          520072|    0.49|          3.12|     0.63|\n",
      "+---------+-----+--------------------+----------+----------------+--------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDestination.filter(~dfDestination.median_age.isNull()).show(5)\n",
    "dfDestination.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build dimFlight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the airline and flightnumber from the *dfImmigrationFinal* dataset and remove rows where airline is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------------+\n",
      "|airline|flightnumber|           flight_id|\n",
      "+-------+------------+--------------------+\n",
      "|     ua|       01011|24f95d9f73a966f6c...|\n",
      "|     af|       00066|3ffda692354ff1379...|\n",
      "|     tn|       00007|eba44be24ebb81276...|\n",
      "+-------+------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10393"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFlight = dfImmigrationFinal \\\n",
    "            .select('airline', 'flightnumber') \\\n",
    "            .drop_duplicates() \\\n",
    "            .filter(~col('airline').isNull()) \n",
    "            \n",
    "dfFlight = dfFlight.withColumn('flight_id', sha2(concat(*(col(c).cast(\"string\") for c in dfFlight.columns)), 256))\n",
    "dfFlight.show(3)\n",
    "dfFlight.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build dimAirport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract destination_city and destination_state and join with *dfAirportsFinal*. Since some cities have more than one airport we remove duplicate city,state. Note that we do not care about getting the \"correct\" airport here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+---------+---------+\n",
      "|          airport_id|                name|latitude|longitude|elevation|\n",
      "+--------------------+--------------------+--------+---------+---------+\n",
      "|ee512688a10599a29...|albuquerque inter...|-106.609|  35.0402|     1632|\n",
      "|f69324430dbf0a266...|ted stevens ancho...|-149.996|  61.1744|       46|\n",
      "|67d6630d1a72c1b1b...|hartsfield jackso...|-84.4281|  33.6367|      312|\n",
      "|46c42052de045246e...|austin bergstrom ...|-97.6699|  30.1945|      165|\n",
      "|b2bb8df6c0f8da84c...|baltimore/washing...|-76.6683|  39.1754|       44|\n",
      "+--------------------+--------------------+--------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAirport = dfImmigrationFinal \\\n",
    "            .select(col('destination_city').alias('city'), col('destination_state').alias('state')) \\\n",
    "            .drop_duplicates()\n",
    "\n",
    "dfAirport = dfAirport.withColumn('airport_id', sha2(concat(*(col(c).cast(\"string\") for c in dfAirport.columns)), 256)) \\\n",
    "            .join(dfAirportsFinal, ['city', 'state']) \\\n",
    "            .drop_duplicates(['city', 'state']) \\\n",
    "            .drop('city', 'state')\n",
    "dfAirport.orderBy('city').show(5)\n",
    "dfAirport.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build factImmigration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate id columns for destination, airport, flight and person by hashing appropriate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----+--------+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|immigration_id|arrival_date|mode|  reason|age|      destination_id|          airport_id|           flight_id|           person_id|\n",
      "+--------------+------------+----+--------+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|       5748517|  2016-04-30| air|business| 40|62cce3579bba26a81...|62cce3579bba26a81...|dff2727479de367c5...|76b293ad639b2757b...|\n",
      "|       5748518|  2016-04-30| air|business| 32|62cce3579bba26a81...|62cce3579bba26a81...|9a3502d3d068dd909...|77032703ae77d5dd6...|\n",
      "|       5748519|  2016-04-30| air|business| 29|62cce3579bba26a81...|62cce3579bba26a81...|293d30efcb1fc3ca7...|9c6c96e256cf1ee8a...|\n",
      "+--------------+------------+----+--------+---+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3096312"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFactImmigration = dfImmigrationFinal \\\n",
    "                    .withColumn('age', when(col('age') <= 0, None).otherwise(col('age'))) \\\n",
    "                    .withColumn('destination_id', sha2(concat(col('destination_city'), col('destination_state')), 256)) \\\n",
    "                    .withColumn('airport_id', sha2(concat(col('destination_city'), col('destination_state')), 256)) \\\n",
    "                    .withColumn('flight_id', sha2(concat(col('airline'), col('flightnumber')), 256)) \\\n",
    "                    .withColumn('person_id', sha2(concat(col('person_birth'), col('person_gender'), col('person_country')), 256)) \\\n",
    "                    .drop('destination_city', 'destination_state', 'person_birth', 'person_gender', 'person_country', 'airline', 'flightnumber')\n",
    "\n",
    "dfFactImmigration.show(3)\n",
    "dfFactImmigration.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPerson.createOrReplaceTempView('person')\n",
    "dfFlight.createOrReplaceTempView('flight')\n",
    "dfAirport.createOrReplaceTempView('airport')\n",
    "dfDestination.createOrReplaceTempView('destination')\n",
    "dfFactImmigration.createOrReplaceTempView('immigration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top immigration origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------+------------------+-----+\n",
      "|             country|mode|  reason|           avg_age|total|\n",
      "+--------------------+----+--------+------------------+-----+\n",
      "|      united kingdom| air|pleasure| 42.41161616161616| 9114|\n",
      "|               japan| air|pleasure|           39.9512| 7502|\n",
      "|mexico air sea, a...| air|pleasure| 42.52473369327302| 6854|\n",
      "|             germany| air|pleasure|41.653202140514416| 5793|\n",
      "|          china, prc| air|pleasure| 44.87930726655954| 5601|\n",
      "+--------------------+----+--------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select country, mode, reason, avg(age) as avg_age, count(*) as total\n",
    "from immigration i\n",
    "join person p on (i.person_id = p.person_id)\n",
    "where arrival_date = '2016-04-30'\n",
    "group by country, mode, reason\n",
    "order by total desc\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top immigration cities and country of origins for sea travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+-----+\n",
      "|      city| state|       country|total|\n",
      "+----------+------+--------------+-----+\n",
      "|hakai pass|canada|     australia|  193|\n",
      "|hakai pass|canada|united kingdom|   99|\n",
      "|hakai pass|canada|    china, prc|   78|\n",
      "|     miami|    fl|united kingdom|   53|\n",
      "|hakai pass|canada|         japan|   47|\n",
      "+----------+------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select city, state, country, count(*) as total\n",
    "from immigration i\n",
    "join destination d on (i.destination_id = d.destination_id)\n",
    "join person p on (i.person_id = p.person_id)\n",
    "where mode = 'sea' and arrival_date = '2016-04-30'\n",
    "group by city, state, country\n",
    "order by total desc\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top countries of origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             country|total|\n",
      "+--------------------+-----+\n",
      "|      united kingdom| 9244|\n",
      "|              france| 6945|\n",
      "|mexico air sea, a...| 6430|\n",
      "|          china, prc| 5736|\n",
      "|               japan| 5736|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "   select country, count(*) as total\n",
    "   from immigration i\n",
    "   join person p on (i.person_id = p.person_id)\n",
    "   where arrival_date = '2016-04-15'\n",
    "   group by country\n",
    "   order by total desc\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "### 4.1 Creating the data model with airflow\n",
    "\n",
    "All pyspark code to build the target data model can be found in *airflow/spark*. The pyspark code will be copied to and executed on the spark cluster using an airflow SSH operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Immigration Data Pipeline](data-pipeline.png \"Immigration Data Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Quality Checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data quality checks are implemented in *airflow/spark/data_quality_check.py*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Airports must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dfAirport.groupBy('name').count().orderBy(desc('count')).first()\n",
    "assert result[1] == 1, \"Airport name must be unique\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All age values must be > 0 or null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dfFactImmigration.where(col('age') <= 0).first()\n",
    "assert result is None, \"Age must not be <= 0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns results for age > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dfFactImmigration.where(col('age') >  30).count()\n",
    "assert result > 30, \"Expected results for age > 30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Airline and flightnumber must be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dfFlight.groupBy('airline', 'flightnumber').count().orderBy(desc('count')).first()\n",
    "assert result[2] == 1, \"Flight airline and flightnumber must be unique\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### United Kingdom should be in top 10 or origin countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the overwhelming part of immigrants is from the UK, 'united kingdom' should always be in the top 10 of immigrant origin countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "   select country, count(*) as total\n",
    "   from immigration i\n",
    "   join person p on (i.person_id = p.person_id)\n",
    "   where arrival_date = '2016-04-20'\n",
    "   group by country\n",
    "   order by total desc\n",
    "\"\"\")\n",
    "\n",
    "first10 = result.take(10)\n",
    "\n",
    "assert \"united kingdom\" in map(lambda x: x[0], first10), \"Expected united kingdom in top 10 origin countries\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_dictionary():    \n",
    "    schema = StructType([ \\\n",
    "        StructField(\"name\", StringType(), True), \\\n",
    "        StructField(\"type\", StringType(), True), \\\n",
    "        StructField(\"description\", StringType(),True), \\\n",
    "    ])\n",
    "    data = [\n",
    "        (\"immigration.immigration_id\", \"string\", \"unique id identifying an immigration event. derived from: i94 cicid converted to integer\"),\n",
    "        (\"immigration.arrival_date\", \"date\", \"date of arrival to us. derived from: i94 dtadfile\"),\n",
    "        (\"immigration.mode\", \"string\", \"travel mode used in the immigration event. derived from: i94 mode. values are air, sea, land, not reported\"),\n",
    "        (\"immigration.reason\", \"string\", \"the reason for the immigration. derived from: i94 visa. values are: business, pleasure, student\"),\n",
    "        (\"immigration.age\", \"integer\", \"age of the immigrant. derived from: i94 bir. rows with values <= 0 have been converted to null.\"),\n",
    "        (\"immigration.destination_id\", \"string\", \"id referencing an immigration destination\"),\n",
    "        (\"immigration.airport_id\", \"string\", \"(if mode == 'air') id referencing the destination airport. important note: the reference to the airport is only established via the destination city and state. therefore the airport might NOT reflect the actual airport used by the immigrant if the city has more than one large airport.\"),\n",
    "        (\"immigration.flight_id\", \"string\", \"(if mode == 'air') id referencing the flight taken by the immigrant\"),\n",
    "        (\"immigration.person_id\", \"string\", \"id referencing immigrant person details\"),\n",
    "        \n",
    "        (\"person.person_id\", \"string\", \"unique id. sha2 hash of (birth_year, gender, country)\"),\n",
    "        (\"person.birth_year\", \"integer\", \"year of birth. derived from: i94 biryear\"),\n",
    "        (\"person.gender\", \"string\", \"gender. derived from: i94 gender. values are f (female) or m (male)\"),\n",
    "        (\"person.country\", \"string\", \"origin country name of immigrant person. derived from: i94 res. values are taken from i94cntyl.\"),\n",
    "        \n",
    "        (\"airport.airport_id\", \"string\", \"sha2 hash of multiple columns to obtain a unique id\"),\n",
    "        (\"airport.name\", \"string\", \"airport name. derived from: airport-codes.csv name\"),\n",
    "        (\"airport.latitude\", \"float\", \"latitude of airport location. derived from: airport-codes.csv coordinates\"),\n",
    "        (\"airport.longitude\", \"float\", \"longitude of airport location. derived from: airport-codes.csv coordinates\"),\n",
    "        (\"airport.elevation\", \"float\", \"elevation in meters of the airport. derived from: airport-codes.csv elevation_ft\"),\n",
    "        \n",
    "        (\"destination.destination_id\", \"string\", \"sha2 hash of (city, state) to obtain a unique id\"),\n",
    "        (\"destination.city\", \"string\", \"city name. derived from: us-cities-demographics 'City'\"),\n",
    "        (\"destination.state\", \"string\", \"state the city is located in. derived from: us-cities-demographics 'State Code'\"),\n",
    "        (\"destination.median_age\", \"float\", \"median age. derived from us-cities-demographics 'Median Age'\"),\n",
    "        (\"destination.total_population\", \"integer\", \"city total population. derived from us-cities-demographics 'Total Population'\"),\n",
    "        (\"destination.male_pct\", \"float\", \"percentage of males. derived from: us-cities-demographics 'Male Population' / 'Total Population'\"),\n",
    "        (\"destination.white_pct\", \"float\", \"percentage of white. derived from: us-cities-demographics 'White Count' / 'Total Population'\"),\n",
    "        (\"destination.household_size\", \"float\", \"average size of household. derived from: us-cities-demographics 'Average Household Size'\"),\n",
    "         \n",
    "        (\"flight.flight_id\", \"string\", \"sha2 hash of (airline, flightnumber) to obtain a unique id\"),\n",
    "        (\"flight.airline\", \"string\", \"airline iata code. derived from: i94 airline\"),\n",
    "        (\"flight.flightnumber\", \"string\", \"flight number. derived from i94 fltno\"),\n",
    "    ]\n",
    "\n",
    "    df = spark.createDataFrame(data=data, schema=schema)\n",
    "    return df\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>immigration.immigration_id</td>\n",
       "      <td>string</td>\n",
       "      <td>unique id identifying an immigration event. derived from: i94 cicid converted to integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>immigration.arrival_date</td>\n",
       "      <td>date</td>\n",
       "      <td>date of arrival to us. derived from: i94 dtadfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>immigration.mode</td>\n",
       "      <td>string</td>\n",
       "      <td>travel mode used in the immigration event. derived from: i94 mode. values are air, sea, land, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>immigration.reason</td>\n",
       "      <td>string</td>\n",
       "      <td>the reason for the immigration. derived from: i94 visa. values are: business, pleasure, student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>immigration.age</td>\n",
       "      <td>integer</td>\n",
       "      <td>age of the immigrant. derived from: i94 bir. rows with values &lt;= 0 have been converted to null.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>immigration.destination_id</td>\n",
       "      <td>string</td>\n",
       "      <td>id referencing an immigration destination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>immigration.airport_id</td>\n",
       "      <td>string</td>\n",
       "      <td>(if mode == 'air') id referencing the destination airport. important note: the reference to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>immigration.flight_id</td>\n",
       "      <td>string</td>\n",
       "      <td>(if mode == 'air') id referencing the flight taken by the immigrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>immigration.person_id</td>\n",
       "      <td>string</td>\n",
       "      <td>id referencing immigrant person details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>person.person_id</td>\n",
       "      <td>string</td>\n",
       "      <td>unique id. sha2 hash of (birth_year, gender, country)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>person.birth_year</td>\n",
       "      <td>integer</td>\n",
       "      <td>year of birth. derived from: i94 biryear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>person.gender</td>\n",
       "      <td>string</td>\n",
       "      <td>gender. derived from: i94 gender. values are f (female) or m (male)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>person.country</td>\n",
       "      <td>string</td>\n",
       "      <td>origin country name of immigrant person. derived from: i94 res. values are taken from i94cntyl.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>airport.airport_id</td>\n",
       "      <td>string</td>\n",
       "      <td>sha2 hash of multiple columns to obtain a unique id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>airport.name</td>\n",
       "      <td>string</td>\n",
       "      <td>airport name. derived from: airport-codes.csv name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>airport.latitude</td>\n",
       "      <td>float</td>\n",
       "      <td>latitude of airport location. derived from: airport-codes.csv coordinates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>airport.longitude</td>\n",
       "      <td>float</td>\n",
       "      <td>longitude of airport location. derived from: airport-codes.csv coordinates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>airport.elevation</td>\n",
       "      <td>float</td>\n",
       "      <td>elevation in meters of the airport. derived from: airport-codes.csv elevation_ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>destination.destination_id</td>\n",
       "      <td>string</td>\n",
       "      <td>sha2 hash of (city, state) to obtain a unique id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>destination.city</td>\n",
       "      <td>string</td>\n",
       "      <td>city name. derived from: us-cities-demographics 'City'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>destination.state</td>\n",
       "      <td>string</td>\n",
       "      <td>state the city is located in. derived from: us-cities-demographics 'State Code'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>destination.median_age</td>\n",
       "      <td>float</td>\n",
       "      <td>median age. derived from us-cities-demographics 'Median Age'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>destination.total_population</td>\n",
       "      <td>integer</td>\n",
       "      <td>city total population. derived from us-cities-demographics 'Total Population'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>destination.male_pct</td>\n",
       "      <td>float</td>\n",
       "      <td>percentage of males. derived from: us-cities-demographics 'Male Population' / 'Total Population'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>destination.white_pct</td>\n",
       "      <td>float</td>\n",
       "      <td>percentage of white. derived from: us-cities-demographics 'White Count' / 'Total Population'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>destination.household_size</td>\n",
       "      <td>float</td>\n",
       "      <td>average size of household. derived from: us-cities-demographics 'Average Household Size'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>flight.flight_id</td>\n",
       "      <td>string</td>\n",
       "      <td>sha2 hash of (airline, flightnumber) to obtain a unique id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>flight.airline</td>\n",
       "      <td>string</td>\n",
       "      <td>airline iata code. derived from: i94 airline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>flight.flightnumber</td>\n",
       "      <td>string</td>\n",
       "      <td>flight number. derived from i94 fltno</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name     type  \\\n",
       "0     immigration.immigration_id   string   \n",
       "1       immigration.arrival_date     date   \n",
       "2               immigration.mode   string   \n",
       "3             immigration.reason   string   \n",
       "4                immigration.age  integer   \n",
       "5     immigration.destination_id   string   \n",
       "6         immigration.airport_id   string   \n",
       "7          immigration.flight_id   string   \n",
       "8          immigration.person_id   string   \n",
       "9               person.person_id   string   \n",
       "10             person.birth_year  integer   \n",
       "11                 person.gender   string   \n",
       "12                person.country   string   \n",
       "13            airport.airport_id   string   \n",
       "14                  airport.name   string   \n",
       "15              airport.latitude    float   \n",
       "16             airport.longitude    float   \n",
       "17             airport.elevation    float   \n",
       "18    destination.destination_id   string   \n",
       "19              destination.city   string   \n",
       "20             destination.state   string   \n",
       "21        destination.median_age    float   \n",
       "22  destination.total_population  integer   \n",
       "23          destination.male_pct    float   \n",
       "24         destination.white_pct    float   \n",
       "25    destination.household_size    float   \n",
       "26              flight.flight_id   string   \n",
       "27                flight.airline   string   \n",
       "28           flight.flightnumber   string   \n",
       "\n",
       "                                                                                            description  \n",
       "0              unique id identifying an immigration event. derived from: i94 cicid converted to integer  \n",
       "1                                                     date of arrival to us. derived from: i94 dtadfile  \n",
       "2   travel mode used in the immigration event. derived from: i94 mode. values are air, sea, land, no...  \n",
       "3       the reason for the immigration. derived from: i94 visa. values are: business, pleasure, student  \n",
       "4       age of the immigrant. derived from: i94 bir. rows with values <= 0 have been converted to null.  \n",
       "5                                                             id referencing an immigration destination  \n",
       "6   (if mode == 'air') id referencing the destination airport. important note: the reference to the ...  \n",
       "7                                   (if mode == 'air') id referencing the flight taken by the immigrant  \n",
       "8                                                               id referencing immigrant person details  \n",
       "9                                                 unique id. sha2 hash of (birth_year, gender, country)  \n",
       "10                                                             year of birth. derived from: i94 biryear  \n",
       "11                                  gender. derived from: i94 gender. values are f (female) or m (male)  \n",
       "12      origin country name of immigrant person. derived from: i94 res. values are taken from i94cntyl.  \n",
       "13                                                  sha2 hash of multiple columns to obtain a unique id  \n",
       "14                                                   airport name. derived from: airport-codes.csv name  \n",
       "15                            latitude of airport location. derived from: airport-codes.csv coordinates  \n",
       "16                           longitude of airport location. derived from: airport-codes.csv coordinates  \n",
       "17                     elevation in meters of the airport. derived from: airport-codes.csv elevation_ft  \n",
       "18                                                     sha2 hash of (city, state) to obtain a unique id  \n",
       "19                                               city name. derived from: us-cities-demographics 'City'  \n",
       "20                      state the city is located in. derived from: us-cities-demographics 'State Code'  \n",
       "21                                         median age. derived from us-cities-demographics 'Median Age'  \n",
       "22                        city total population. derived from us-cities-demographics 'Total Population'  \n",
       "23     percentage of males. derived from: us-cities-demographics 'Male Population' / 'Total Population'  \n",
       "24         percentage of white. derived from: us-cities-demographics 'White Count' / 'Total Population'  \n",
       "25             average size of household. derived from: us-cities-demographics 'Average Household Size'  \n",
       "26                                           sha2 hash of (airline, flightnumber) to obtain a unique id  \n",
       "27                                                         airline iata code. derived from: i94 airline  \n",
       "28                                                                flight number. derived from i94 fltno  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDD = create_data_dictionary()\n",
    "pd.set_option(\"max_colwidth\", 100)\n",
    "dfDD.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data pipeline project uses the following tools:\n",
    "    \n",
    "- spark and pyspark for ELT\n",
    "- apache airflow to orchestrate the data pipeline\n",
    "- AWS EMR as a cloud spark cluster\n",
    "- AWS S3 as a data store for input and output files\n",
    "    \n",
    "I decided to use **pyspark** for data processing because of the disparate nature of the raw data sources (parquet files and csv) and the need for some more complex data transformations (e. g. parsing the i94 port codes). It seems to be a better and more flexible choice than using AWS redshift and sql scripts as the alternative.\n",
    "Furthermore pyspark is also very scalable and well suited for a data lake approach which would be useful if new data sources (or just new data attributes) need to be incorporated into the pipeline or further requirements regarding the target analytics schema might arise. \n",
    "\n",
    "**Airflow** is probably useful in any data pipeline project for pipeline orchestration, handling retries and backfilling or just as a graphical user interface to troubleshoot and monitor pipeline runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update frequency of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally the update frequency of the data depends on the analytical purposes, so for example if you are looking for a report on immigration to the US once a year then once a year would be enough. However if you want to know what's happening every day or want to go even more realtime like hourly, then of course the pipeline has to run much more frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|arrival_date| total|\n",
      "+------------+------+\n",
      "|  2016-04-30|125570|\n",
      "|  2016-04-29|120497|\n",
      "|  2016-04-17|119296|\n",
      "|  2016-04-28|116601|\n",
      "|  2016-04-15|109746|\n",
      "+------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select arrival_date, count(*) as total from immigration\n",
    "group by arrival_date\n",
    "order by total desc\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the query above we can see that we have about 120k - 130k immigration events to process per day. So daily updates would be no problem at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37685, 282, 67, 10393)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPerson.count(), dfDestination.count(), dfAirport.count(), dfFlight.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers above show that the dimension tables are quite small. Biggest is dfPerson which will certainly grow with more data. However all in all still no problem to update daily or even more frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data increases 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So data increasing 100x means instead of a 130k we would have 13m daily events. In this case we should definitely switch to daily processing to keep the amount of data relatively small and limited. \n",
    "Input immigration data would have to be partitioned by day and put into corresponding source parquet files.\n",
    "We can then leverage airflow to process the daily input files and append new data to our target analytics database.\n",
    "\n",
    "Given AWS EMR scalability (more and/or faster cluster nodes) updating the target database daily should pose no problem even with an 100x increase in data. However processing time might increase from a couple of minutes to hours depending on the compute resources in the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate a dashboard daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to populate a dashboard daily with immigration data we should switch to daily processing as described above. We can then configure our airflow dag to run nightly and should have the up to date data ready in our dashboard in the morning by 7am."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database accessed by 100+ people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the extreme case our database would have to handle 100 analytical queries concurrently. Again given the scalability of AWS EMR every user could just start his own EMR cluster, load the target data and start analyzing (assuming all users use jupyter notebooks). This would definitely scale however it would also not be a very cost efficient solution. To improve the situation multiple users (say 10) could share an EMR cluster for their analytics purposes. This seems more like a cost effective solution.\n",
    "\n",
    "A different scenario would be a web application serving 100+ users and accessing the target database or 100+ users with SQL clients wanting to access the target database. In such cases spark is not the best tool and we could additionally start up a AWS redshift instance and import the target database using the output parquet files on Amazon S3. Our users would then access redshift and perform their queries. With redshift being also very scalable again this should be no problem at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
